"""
    Generate, from a processed vulnerability .xlsx file, a .xlsx and a .csv
    file to open Jira tickets for every vulnerability found.
"""
import argparse
import os
import sys
import logging.config
from datetime import datetime
from time import time

import pandas as pd

from lib.utility_lib import (check_python_and_pandas_version, colour_text,
                             config_file_to_dictionary,
                             create_working_dir_and_remove_tree_if_exists,
                             get_data_from_yaml_file,
                             get_df_from_spreadsheet_file,
                             set_postfix_file_name, strict_types,
                             write_sheet_to_excel,
                             MyColours)

# Configuration file
CONFIG_PROPERTY_FILE = './config_properties.yml'
CSV_PROPERTIES_SECTION = "csv_generator_properties"
VULNERABILITY_PROPERTIES_SECTION = "vulnerability_properties"

# CONSTANTS
CONFLUENCE_URL = "https://eteamspace.internal.ericsson.com/"
DOC_URL = CONFLUENCE_URL + "display/ENMRASecurity/" \
          "Security+VA+Scan+Report+Analisys+and+CVE+jira+management"
FAKE_CVE_URL = CONFLUENCE_URL + "display/ENMRASecurity/CVEs+-+False+Positive"
FOSS_URL = CONFLUENCE_URL + "display/3PPP/FOSS+HomePage"

COLUMNS_ORDER = [
    'Issue Type', 'Summary', 'Priority', 'Reporter', 'Description',
    'Team name', 'RA', 'Component/s', 'Acceptance Criteria',
    'Found in release', 'Epic Link', 'Product Name',
    'Product Number', 'Severity', 'Tool', 'Identifier',
    'Vulnerability description'
]

COLUMNS_TO_REMOVE = [
    'CNA', 'Image Name', 'Image Version', 'Package Name', 'Package Version',
    'Package Family', 'Package Paths', 'VulnerabilityID', 'Fixed Versions',
    'Image Path', 'Rpm Name', 'Rpm Version', 'CXP from Rpm Name', 'CXP'
]
OUTPUT_FOLDER = "./output_tables/"
PREFIX_FILE_NAME = OUTPUT_FOLDER + "cENM-cve-jira-csv_"
ADDITIONAL_INFO_SEPARATOR = "|"
ADDITIONAL_INFO_GRYPE_TRIVY = "Description: "
ADDITIONAL_INFO_XRAY = "Summary: "
GENERIC_RPM_VERSION = "x.y.z"
logging.config.dictConfig(get_data_from_yaml_file('logging.yaml'))
logger = logging.getLogger("csv_for_jira_generator")


@strict_types
def validate_existing_file(file_name: str) -> str:
    """
    Check that the given file name is an existing file
    Args:
        file_name: the string containing the full name of a file

    Returns:
        the same file name if the file exist, otherwise it raises an exception
    """
    if os.path.exists(file_name):
        return file_name

    raise argparse.ArgumentTypeError(
            f"Enter a valid input file. '{file_name}' not found!")


@strict_types
def save_report_files(df: pd.DataFrame, csv_dictionary: dict, postfix: str):
    """
    Create folder and save report files
    """
    prefix_file_name = PREFIX_FILE_NAME + set_postfix_file_name(
        csv_dictionary['enm_product_set'], postfix)

    # Output folder and files creation
    create_working_dir_and_remove_tree_if_exists(OUTPUT_FOLDER, False)
    file_name = prefix_file_name + ".csv"
    df.to_csv(file_name, index=False)
    logger.info("Generated output file: %s", file_name)

    file_name = prefix_file_name + ".xlsx"
    # Save the data frame to the Excel file and close it
    write_sheet_to_excel(file_name, df)
    logger.info("Generated output file: %s", file_name)


@strict_types
def define_description_header(iso_version: str, enm_product_set: str, sprint_version: str) -> str:
    """
    Define the description field header
    Args:
        iso_version: the ISO version of the report
        enm_product_set: the enm product set of the report
        sprint_version: the sprint version of the report

    Returns:
        the summary header description
    """
    return "This task is auto generated by the system in order " \
           "to address the clean-up of CVE instance in ENM.\n\n" \
           "Please look at this Confluence link for more details:\n" \
           f"{DOC_URL}\n\n" \
           "Before starting analysis verify if the CVE is not defined as " \
           "fake at the following page:\n" \
           f"{FAKE_CVE_URL}\n\n" \
           "When a CVE is found on an RPM without an associated version, " \
           "please refer to the RPM version contained " \
           f"in ISO {iso_version}\n\n" \
           "When doing a version uplift for FOSS or when introducing " \
           "new FOSS, make sure you have approval in SCAS and the " \
           "3PP database for that version of FOSS in ENM.\n" \
           f"Info available here: {FOSS_URL}\n\n" \
           "--- PLEASE DON'T CHANGE TASK SUMMARY ---\n\n" \
           "--- Sprint details ---\n" \
           f"Found in ISO version: {iso_version}\n" \
           f"Found in Product Set version: {enm_product_set}\n" \
           f"Found in Sprint version: {sprint_version}\n\n"


@strict_types
def define_description_data(df_row: pd.Series, rpm_found: bool) -> str:
    """
    Define the common description used in the final output
    Args:
        df_row: the source row
        rpm_found: true if the RPM name is found, false otherwise

    Returns:
        the commons description
    """
    description = "Found on image: " + df_row['Image Path']
    if rpm_found:
        description += "\nFound on RPM: " + df_row['Rpm Name']
        if df_row['Rpm Version'] != GENERIC_RPM_VERSION:
            description += "::" + df_row['Rpm Version']

    description += \
        "\n3PP package: " + df_row['Package Name'] \
        + "\n3PP package version: " + df_row['Package Version'] \
        + "\n3PP fixed version: " + df_row['Fixed Versions'] \
        + "\n" + df_row['Found in'] \
        + "\nPackage paths: " + df_row['Package Paths']

    return description


@strict_types
def define_description_field(df_row: pd.Series, b_rpm_name_found: bool) -> str:
    """
    Define the description field
    Args:
        df_row: the source row
        b_rpm_name_found: True if the RPM name was found, False otherwise

    Returns:
        the description field
    """
    return "\n--- Instance ---\n" \
           + define_description_data(df_row, b_rpm_name_found) \
           + "\n----------------\n"


@strict_types
def exceed_cell_limit_message() -> str:
    """
    Return a cell limit warning message
    """
    return f"""\n\nWARNING! Cell limit reached!

The description may not be complete and some images and package path \
might be missing.

Please refer to the complete report available on page:
    {DOC_URL}\n\n
    """


@strict_types
def merge_description_fields(df: pd.DataFrame,
                             csv_dictionary: dict,
                             vulnerability_dictionary: dict) -> pd.DataFrame:
    """
    Merge all duplicated description and return a new data frame
    Args:
        df: the source data frame
        csv_dictionary: dictionary of Jira settings
        vulnerability_dictionary: dictionary of ER settings

    Returns:
        a data frame containing rows with merged description
    """
    # Add column to detect if the row was already merged. Default value: False
    df['Merged'] = False

    for index, row in df.iterrows():
        if not df.at[index, 'Merged']:
            # Set duplicates_df with duplicate records
            duplicates_df = df.loc[(df['Summary'] == row['Summary'])
                                   & (~df['Merged'])]
            duplicates_df.sort_index(inplace=True)

            skipped_row = 0
            description = info_msg = ""
            for index_duplicate, duplicate_row in duplicates_df.iterrows():
                if index_duplicate == index:
                    description = define_description_header(
                        csv_dictionary['iso_version'],
                        csv_dictionary['enm_product_set'],
                        csv_dictionary['sprint_version'])
                else:
                    # Set 'Merged' field to 'True'
                    df.at[index_duplicate, 'Merged'] = True

                if skipped_row:
                    skipped_row += 1
                    continue

                description_item = define_description_field(
                    duplicate_row, duplicate_row["Rpm Name"] != "None")

                # Check if 'description' length exceed the cell limit
                if len(description + description_item +
                       exceed_cell_limit_message()) > vulnerability_dictionary[
                           'description_length_limit']:
                    description += exceed_cell_limit_message()
                    info_msg = f"On record '{duplicate_row['Summary']}' " \
                               "the description exceed the cell limit."
                    skipped_row += 1
                else:
                    description += description_item

            df.at[index, 'Description'] = description
            if skipped_row:
                logger.info("%s Due to this, %d record/s was skipped.",
                            info_msg, skipped_row)

    # Remove all entries with value 'Merged' == False from df
    df = df[~df['Merged']].copy()

    # Remove the 'Merged' column
    df.drop('Merged', axis=1, inplace=True)

    return df


@strict_types
def define_jira_priority(severity: str) -> str:
    """
    Return the Jira priority value from the vulnerability severity value
    Args:
        severity: the vulnerability severity value

    Returns:
        the Jira priority value
    """
    jira_priority_dict = {
        'critical': 'Critical',
        'high': 'Major',
        'medium': 'Minor',
        'low': 'Minor'
    }

    jira_priority = jira_priority_dict.get(severity.lower())
    if jira_priority is None:
        logger.error(
            colour_text(
                MyColours.RED,
                f"Unprocessed vulnerability severity value: {severity}"))
        sys.exit(1)

    return jira_priority


@strict_types
def fill_summary_field(df: pd.DataFrame) -> pd.DataFrame:
    """
    Fill the 'Summary' field
    Args:
        df: the data frame
    """
    df_rpm = df.loc[(df['Rpm Name'] != 'None')].copy()
    df_rpm['Summary'] = df_rpm['CVE-REF'] + " found on 3PP " + df_rpm[
        'Package Name'] + " included in " + df_rpm['Rpm Name']

    df_rpm_not_found = df.loc[(df['Rpm Name'] == 'None')].copy()
    df_rpm_not_found['Summary'] = df_rpm_not_found[
        'CVE-REF'] + " found on 3PP " + df_rpm_not_found[
            'Package Name'] + " included in " + df_rpm_not_found['Image Name']

    return pd.concat([df_rpm_not_found, df_rpm], ignore_index=True)


@strict_types
def fill_priority_field(df: pd.DataFrame):
    """
    Fill the 'Priority' field
    Args:
        df: the data frame
    """
    for index, row in df.iterrows():
        df.at[index, 'Priority'] = define_jira_priority(row['Priority'])


@strict_types
def set_vulnerability_description_field(df: pd.DataFrame):
    """
    Set the 'Vulnerability description' fields
    Args:
        df: the data frame
    """
    for row_index, row in df.iterrows():
        for item in str.split(row['Vulnerability description'],
                              ADDITIONAL_INFO_SEPARATOR):
            if item.startswith(ADDITIONAL_INFO_GRYPE_TRIVY):
                df.at[row_index, 'Vulnerability description'] = item[
                    len(ADDITIONAL_INFO_GRYPE_TRIVY):]
                break

            if item.startswith(ADDITIONAL_INFO_XRAY):
                df.at[row_index, 'Vulnerability description'] = item[
                    len(ADDITIONAL_INFO_XRAY):]
                break


@strict_types
def create_jira_ticket_df(df: pd.DataFrame, csv_dictionary: dict,
                          vulnerability_dictionary: dict) -> pd.DataFrame:
    """
    Generate a dataframe to be used by the Jira ticket script
    Args:
        df: the report dataframe
        csv_dictionary: dictionary of Jira settings
        vulnerability_dictionary: dictionary of Exemption Request settings
    Returns:
        processed dataframe
    """
    # Set filter to remove duplicate entry on input data frame
    remove_duplicate_rows_by_columns = [
        'CVE-REF', 'Package Name', 'Rpm Name', 'Image Name', 'Fixed Versions',
        'Found in', 'Severity', 'Package Paths'
    ]
    df = df.drop_duplicates(subset=remove_duplicate_rows_by_columns)

    # Remove unnamed columns
    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]

    df['Summary'] = pd.NA
    df = fill_summary_field(df)

    df['Priority'] = df['Severity']  # Create 'Priority' column from 'Severity'
    fill_priority_field(df)

    df['Description'] = pd.NA
    df = merge_description_fields(df, csv_dictionary, vulnerability_dictionary)

    # Rename column 'Team'
    df = df.rename(columns={'Team': 'Team name'})

    # Remove not required columns
    df.drop(columns=COLUMNS_TO_REMOVE, axis=1, inplace=True)

    # Rename column
    df = df.rename(columns={'Found in': 'Tool'})  # Exemption request field
    df = df.rename(columns={'CVE-REF':
                            'Identifier'})  # Exemption request field
    df = df.rename(columns={'Additional Info': 'Vulnerability description'
                            })  # Exemption request field

    # Add columns
    df['Issue Type'] = vulnerability_dictionary['jira_type'].capitalize()
    df['Reporter'] = "Admin"
    df['Component/s'] = "CVE_ISSUE_AUTO_TASK"
    df['Acceptance Criteria'] = "Uplift or remove(if not used) the " \
                                "vulnerable components"
    df['Found in release'] = csv_dictionary['found_in_release']
    df['Epic Link'] = vulnerability_dictionary['epic']
    df['Product Name'] = vulnerability_dictionary[
        'product_name']  # Exemption request field
    df['Product Number'] = vulnerability_dictionary[
        'product_number']  # Exemption request field
    df['Severity'] = df['Severity'].apply(lambda x: x.capitalize())

    # Remove and ordering columns
    df = df[COLUMNS_ORDER]

    # Managing 'Tool' field
    df['Tool'] = df['Tool'].apply(lambda x: x.replace('Found in ', ''))

    # Managing 'Additional info' field
    set_vulnerability_description_field(df)

    return df


@strict_types
def csv_for_jira_generator(file: str, date_and_time: str):
    """
    Generate the file to create the Jira ticket.
    Args:
        file: file name
        date_and_time: date and time to add at the generated output file name
    """
    start_time = time()
    if not os.path.exists(file):
        logger.error(
            colour_text(MyColours.RED,
                        f"Enter a valid input file. '{file}' not found!"))
        sys.exit(1)

    # Load report file
    va_report_df = get_df_from_spreadsheet_file(os.path.normpath(file))
    if va_report_df is None:
        logger.error(
            colour_text(MyColours.RED,
                        f"Impossible to load input file '{file}."))
        sys.exit(1)

    # Read configuration file
    cvs_dictionary = config_file_to_dictionary(CONFIG_PROPERTY_FILE,
                                               CSV_PROPERTIES_SECTION)
    vulnerability_dictionary = \
        config_file_to_dictionary(CONFIG_PROPERTY_FILE,
                                  VULNERABILITY_PROPERTIES_SECTION)

    if vulnerability_dictionary['description_length_limit'] < \
            len(exceed_cell_limit_message()):
        logger.error(
            colour_text(
                MyColours.RED, "The size of the cell length "
                f"{vulnerability_dictionary['description_length_limit']} "
                "is minor of the exceed cell limit message length "
                f"{len(exceed_cell_limit_message())}!"))

        sys.exit(1)

    va_report_df = va_report_df.reindex()

    va_report_df = create_jira_ticket_df(va_report_df, cvs_dictionary,
                                         vulnerability_dictionary)

    save_report_files(va_report_df, cvs_dictionary, date_and_time)

    execution_time = time() - start_time
    logger.info(
        colour_text(MyColours.YELLOW,
                    f'Execution time: {execution_time: .2f}s'))


def main():
    """
    The script generate a CSV output file from a processed scan report to
    automatically create Jira tickets.
    The result is saved to an Excel file.
    """
    check_python_and_pandas_version(str(sys.version_info.major), "3",
                                    str(pd.__version__), "2")

    parser = argparse.ArgumentParser(
        description="The script generate a CSV output file from a processed "
        "scan report to automatically create Jira tickets."
        "The result is saved in an Excel file.")
    parser.add_argument('-f',
                        '--file',
                        type=validate_existing_file,
                        required=True,
                        help="the full path of the VA report file")
    parser.add_argument('-d',
                        '--date',
                        type=str,
                        required=False,
                        default='',
                        help="the date and time to add at the file name")

    if len(sys.argv) == 1:
        parser.print_help()
        sys.exit(1)

    args = parser.parse_args()

    if args.date is None or len(args.date) == 0:
        date_and_time = datetime.today().strftime("%Y-%m-%d_%H_%M_%S")
    else:
        date_and_time = args.date

    csv_for_jira_generator(args.file, date_and_time)


if __name__ == '__main__':
    main()
